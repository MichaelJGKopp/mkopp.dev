# Usage Instructions:
# 1. Make a copy of this file and name it ".env"
# 2. Replace the placeholder values with your actual configuration details.
# 3. This .env file is used by Docker Compose to configure the services.
#    It should not be committed to version control.

# Reverse Proxy
TRAEFIK_ACME_EMAIL=your-email@example.com
TRAEFIK_HTTP_RULE=Host(`your-domain.com`) || Host(`www.your-domain.com`)
TRAEFIK_HTTP_BACKEND_RULE=Host(`api.your-domain.com`)
# AUTH Dashboard
# user -> echo $(htpasswd -Bnb your_username your_password) | sed -e 's/\$/\$\$/g'
TRAEFIK_AUTH_USER=your_username

# Database
POSTGRES_HOST=postgres:5432 # use 'localhost:5555' for local development with a local Postgres instance
POSTGRES_DB=your_postgres_db
POSTGRES_SCHEMA=mysite
POSTGRES_USER=your_postgres_user
POSTGRES_PASSWORD=your_postgres_password # Use this for both dev and prod (direct env var)

# Keycloak
KEYCLOAK_HOSTNAME=auth.your-production-domain.com # Public hostname for Keycloak in production
KEYCLOAK_HTTP_RULE=Host(`${KEYCLOAK_HOSTNAME}`) # Production HTTP rule
KEYCLOAK_ISSUER_URI=https://${KEYCLOAK_HOSTNAME}/realms/mkopp # Production issuer URI
KEYCLOAK_JWK_SET_URI=http://keycloak:8080/realms/mkopp/protocol/openid-connect/certs # Internal URI for JWK set (used by backend)
KEYCLOAK_ADMIN=admin
KEYCLOAK_ADMIN_PASSWORD=admin

# Backend
CORS_ALLOWED_ORIGINS=https://mkopp.dev,https://www.mkopp.dev
# Backend - Debug
CONTROLLER_LOGGING_ASPECT_LEVEL=ERROR
CONTROLLER_LOGGING_REQUEST_ARGS=false
SERVICE_LOGGING_ASPECT_LEVEL=ERROR
SERVICE_LOGGING_REQUEST_ARGS=false

# Frontend - Debug
LOG_REQUESTS=false #true
DEBUG= #*

# VPS project root folder
DEPLOY_PATH=/path/to/your/project

DOCKERHUB_USERNAME=your_dockerhub_username

# AI Settings
# Gemini
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
GEMINI_MODEL=gemini-2.5-flash
# Local LLM or GPT, even Gemini via OpenAI API compatibility
LLM_API_KEY=dummy_or_gpt_api_key_here
LLM_API_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai
LLM_API_COMPLETIONS_PATH=/chat/completions
LLM_MODEL=gemini-2.5-flash-lite